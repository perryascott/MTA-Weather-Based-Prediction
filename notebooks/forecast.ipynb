{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz, os, sys, warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from scripts.decomposition import perform_mstl\n",
    "from scripts.ingest import build_mta_df, get_combined_residuals_df\n",
    "from scripts.filter import split_df_at_datetime, TimeInterval\n",
    "from scripts.model import *\n",
    "from scripts.parameter_search import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_path = os.path.join(os.getcwd(), '..', 'assets')\n",
    "\n",
    "hourly_subway_df, hourly_bus_df, weather_df = build_mta_df(\n",
    "    os.path.join(assets_path, 'hourly_subway_ridership.csv'),\n",
    "    os.path.join(assets_path, 'hourly_bus_ridership.csv'),\n",
    "    os.path.join(assets_path, 'nyc_hourly_weather.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MSTL decomposition for subway data\n",
    "subway_decomposition = perform_mstl(hourly_subway_df['total_ridership'], periods=[24, 24*7])\n",
    "\n",
    "# Perform MSTL decomposition for bus data\n",
    "bus_decomposition = perform_mstl(hourly_bus_df['total_ridership'], periods=[24, 24*7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_residuals_df(hourly_subway_df, hourly_bus_df, weather_df, subway_decomposition, bus_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include rows with precipitation > 0\n",
    "rainy_df = combined_df[combined_df['Precipitation (in)'] > 0].copy()\n",
    "print(f\"Original dataset size: {len(combined_df)}\")\n",
    "print(f\"Dataset size with only precipitation > 0: {len(rainy_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "time_intervals = [\n",
    "    TimeInterval('Spring', 'weekend', (12, 14))\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    # 'Linear': LinearModel(),\n",
    "    # 'GLM': GLMModel(),\n",
    "    # 'Quantile': QuantileModel(quantile=0.5),\n",
    "    # 'Robust': RobustModel(),\n",
    "    'GradientBoosting': GradientBoostingModel(),\n",
    "    # 'XGBoost': XGBoostModel(n_estimators=10),\n",
    "    # 'Naive': NaiveModel()\n",
    "}\n",
    "\n",
    "train_df, val_df = split_df_at_datetime(rainy_df, pd.Timestamp('2023-11-16'))\n",
    "\n",
    "results = {}\n",
    "\n",
    "modes = ['subway', 'bus']\n",
    "\n",
    "for time_interval in time_intervals:\n",
    "    for mode in modes:\n",
    "        print(f\"\\nAnalysis for {mode.capitalize()} - {time_interval.summary}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # results = run_model_analysis(models, combined_df, mode, season, day_type, hours)\n",
    "        \n",
    "        # for model_name, result in results.items():\n",
    "        #     print(f\"\\n{model_name} Results:\")\n",
    "        #     print(\"Metrics:\", result['train_metrics'])\n",
    "        #     print(\"Summary:\", result['summary'])\n",
    "\n",
    "        results[f'{mode}_{time_interval.summary}'] = run_model_analysis(models, train_df, mode, time_interval, val_df)\n",
    "\n",
    "        for model_name, result in results[f'{mode}_{time_interval.summary}'].items():\n",
    "            print(f\"\\n{model_name} Results:\")\n",
    "            print(\"Train Metrics:\", result['train_metrics'])\n",
    "            print(\"Train Residuals:\", result['train_residual'])\n",
    "            print(\"Validation Metrics:\", result['val_metrics'])\n",
    "            print(\"Validation Residuals:\", result['val_residual'])\n",
    "            print(\"Summary:\", result['summary'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots comparing train vs validation MAE for each condition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', rotation=90)\n",
    "\n",
    "# Create a plot for each condition\n",
    "for time_interval in time_intervals:\n",
    "    for mode in modes:\n",
    "        \n",
    "        # Extract results for this condition\n",
    "        condition_results = results[f'{mode}_{time_interval.summary}']\n",
    "        \n",
    "        # Extract MAE values for each model\n",
    "        model_names = list(condition_results.keys())\n",
    "        train_maes = [result['train_metrics']['MAE'] for result in condition_results.values()]\n",
    "        val_maes = [result['val_metrics']['MAE'] for result in condition_results.values()]\n",
    "        \n",
    "        # Calculate mean absolute residuals\n",
    "        train_residuals = np.mean([abs(result['train_residual']) for result in condition_results.values()])\n",
    "        val_residuals = np.mean([abs(result['val_residual']) for result in condition_results.values()])\n",
    "\n",
    "        # Set up bar plot\n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        train_bars = ax.bar(x - width/2, train_maes, width, label='Train MAE')\n",
    "        val_bars = ax.bar(x + width/2, val_maes, width, label='Validation MAE')\n",
    "        \n",
    "        # Add horizontal lines for mean absolute residuals\n",
    "        ax.axhline(y=train_residuals, color='blue', linestyle=':', label='Train Mean Absolute Residual')\n",
    "        ax.axhline(y=val_residuals, color='orange', linestyle=':', label='Validation Mean Absolute Residual')\n",
    "\n",
    "        # Customize plot\n",
    "        ax.set_ylabel('Mean Absolute Error')\n",
    "        ax.set_title(f'Model Performance Comparison: {mode.capitalize()} - {time_interval.summary}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(model_names)\n",
    "        ax.legend()\n",
    "\n",
    "        # Add value labels on bars\n",
    "        autolabel(ax, train_bars)\n",
    "        autolabel(ax, val_bars)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific statsmodels warning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='statsmodels')\n",
    "\n",
    "# hour_ranges = [(0,2),(2, 4),(4, 6),(6, 8),(8, 10),(10, 12),(12, 14),(14, 16),(16, 18),(18, 20),(20, 22),(22, 24)]\n",
    "hour_ranges = [(0,4),(4,8),(8,12),(12,16),(16,24)]\n",
    "\n",
    "# weekend_day_types = ['weekend', 'weekday']\n",
    "weekend_day_types = ['weekend']\n",
    "season = 'Spring'\n",
    "\n",
    "time_intervals = [TimeInterval(season, wd_type, hour_range) for wd_type in weekend_day_types for hour_range in hour_ranges]\n",
    "\n",
    "# Check that time interval has at least N points in train and val, otherwise exclude\n",
    "def sufficient_dataset_size(ti, train_df, val_df, n=15):\n",
    "    train_df = ti.filter(train_df)\n",
    "    val_df = ti.filter(val_df)\n",
    "    cond = len(train_df) >= n and len(val_df) >= n\n",
    "    if not cond:\n",
    "        print(f\"Removing time interval {ti.summary}\") \n",
    "    return cond\n",
    "time_intervals = [ti for ti in time_intervals if sufficient_dataset_size(ti, train_df, val_df)]\n",
    "\n",
    "# Get all possible feature combinations\n",
    "feature_combinations = generate_feature_combinations([\n",
    "    ModelParameters.TEMPERATURE,\n",
    "    ModelParameters.PRECIPITATION, \n",
    "    ModelParameters.HUMIDITY,\n",
    "    ModelParameters.CLOUD_COVER,\n",
    "    ModelParameters.PRESSURE\n",
    "])\n",
    "\n",
    "# print(f\"Number of feature combinations: {len(feature_combinations)}\")\n",
    "# for i, combo in enumerate(feature_combinations):\n",
    "#     print(f\"{i}: {combo}\")\n",
    "\n",
    "# Run parameter search for each mode\n",
    "modes = ['subway', 'bus']\n",
    "search_results = {}\n",
    "\n",
    "for mode in modes:\n",
    "    # Evaluate models with different parameter combinations\n",
    "    mode_results = search_models_and_parameters(\n",
    "        models=models,\n",
    "        train_data=train_df,\n",
    "        val_data=val_df,\n",
    "        mode=mode,\n",
    "        time_intervals=time_intervals,\n",
    "        parameter_combinations=feature_combinations\n",
    "    )    \n",
    "    # Store results\n",
    "    search_results[mode] = mode_results\n",
    "\n",
    "\n",
    "    ordered_mode_results = order_averaged_scores(mode_results, mae_objective)\n",
    "\n",
    "    print(f\"Ordered mode results {ordered_mode_results}:\")\n",
    "    # Print top 5 feature combinations for this mode\n",
    "    n = 50\n",
    "    print(f\"\\nTop {n} feature combinations for {mode}:\")\n",
    "    for (model_name, params, score) in ordered_mode_results[:n]:\n",
    "        param_names = [p.value for p in params]\n",
    "        print(f\"Score: {score:.4f} - Features: {param_names} - Model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_by_interval(search_results, mode, day_type):\n",
    "    best_models = {}\n",
    "    \n",
    "    # Get all results for this mode\n",
    "    mode_results = search_results[mode]\n",
    "    \n",
    "    # Filter results by day type and find best model for each interval\n",
    "    for result in mode_results:\n",
    "        interval = result[\"time_interval\"]\n",
    "        if interval.day_type != day_type:\n",
    "            continue\n",
    "            \n",
    "        model_results = result[\"model_results\"]\n",
    "        parameters = result[\"parameters\"]\n",
    "        \n",
    "        # Initialize best configuration for this interval if not exists\n",
    "        if interval not in best_models:\n",
    "            best_models[interval] = {\n",
    "                'model_name': None,\n",
    "                'features': None,\n",
    "                'train_mae': float('inf'),\n",
    "                'val_mae': float('inf'),\n",
    "                'val_residual': None,\n",
    "                'val_residual_actual': None,\n",
    "                'val_residual_preds': None,\n",
    "                'n_samples': 0\n",
    "            }\n",
    "            \n",
    "        # Check each model's performance\n",
    "        for model_name, metrics in model_results.items():\n",
    "            val_mae = metrics['val_metrics']['MAE']\n",
    "            if val_mae < best_models[interval]['val_mae']:\n",
    "                best_models[interval] = {\n",
    "                    'model_name': model_name,\n",
    "                    'features': [p.value for p in parameters],\n",
    "                    'train_mae': metrics['train_metrics']['MAE'],\n",
    "                    'val_mae': val_mae,\n",
    "                    'val_residual': metrics['val_residual'],\n",
    "                    'val_residual_actual': metrics['val_residual_actual'],\n",
    "                    'val_residual_preds': metrics['val_residual_preds'],\n",
    "                    'n_samples_val': len(metrics['val_residual']),\n",
    "                    'n_samples_train': len(metrics['train_residual'])\n",
    "                }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Create plots for each mode and day type\n",
    "for mode in modes:\n",
    "    for day_type in ['weekend', 'weekday']:\n",
    "        best_models = get_best_models_by_interval(search_results, mode, day_type)\n",
    "        \n",
    "        # Create subplots for each time interval\n",
    "        n_intervals = len(best_models)\n",
    "        fig, axes = plt.subplots(n_intervals, 1, figsize=(15, 8*n_intervals))\n",
    "        if n_intervals == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for idx, (interval, model) in enumerate(best_models.items()):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Plot actual vs predicted values\n",
    "            ax.scatter(model['val_residual_actual'], model['val_residual_preds'], alpha=0.5)\n",
    "            \n",
    "            # Get min/max for equal scaling\n",
    "            min_val = min(min(model['val_residual_actual']), min(model['val_residual_preds']))\n",
    "            max_val = max(max(model['val_residual_actual']), max(model['val_residual_preds']))\n",
    "            abs_max = max(abs(min_val), abs(max_val))\n",
    "            \n",
    "            # Set equal limits centered on 0\n",
    "            ax.set_xlim(-abs_max, abs_max)\n",
    "            ax.set_ylim(-abs_max, abs_max)\n",
    "            \n",
    "            # Plot perfect prediction line\n",
    "            ax.plot([-abs_max, abs_max], [-abs_max, abs_max], 'r--', label='Perfect Prediction')\n",
    "            \n",
    "            # Set aspect ratio to 1\n",
    "            ax.set_aspect('equal')\n",
    "            \n",
    "            # Customize plot\n",
    "            ax.set_xlabel('Actual Values')\n",
    "            ax.set_ylabel('Predicted Values')\n",
    "            ax.set_title(f'{interval.summary}\\nModel: {model[\"model_name\"]}, Features: {\", \".join(model[\"features\"])}\\nMAE: {model[\"val_mae\"]:.4f}')\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add R-squared value\n",
    "            r2 = np.corrcoef(model['val_residual_actual'], model['val_residual_preds'])[0,1]**2\n",
    "            ax.text(0.05, 0.95, f'R² = {r2:.4f}', transform=ax.transAxes)\n",
    "            \n",
    "        plt.suptitle(f'Actual vs Predicted Values\\n{mode.capitalize()} - {day_type.capitalize()}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
