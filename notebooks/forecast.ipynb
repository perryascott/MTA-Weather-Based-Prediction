{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz, os, sys, warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from scripts.decomposition import perform_mstl\n",
    "from scripts.ingest import build_mta_df, get_combined_residuals_df\n",
    "from scripts.filter import split_df_at_datetime, TimeInterval\n",
    "from scripts.model import *\n",
    "from scripts.parameter_search import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_path = os.path.join(os.getcwd(), '..', 'assets')\n",
    "\n",
    "hourly_subway_df, hourly_bus_df, weather_df = build_mta_df(\n",
    "    os.path.join(assets_path, 'hourly_subway_ridership.csv'),\n",
    "    os.path.join(assets_path, 'hourly_bus_ridership.csv'),\n",
    "    os.path.join(assets_path, 'nyc_hourly_weather.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MSTL decomposition for subway data\n",
    "subway_decomposition = perform_mstl(hourly_subway_df['total_ridership'], periods=[24, 24*7])\n",
    "\n",
    "# Perform MSTL decomposition for bus data\n",
    "bus_decomposition = perform_mstl(hourly_bus_df['total_ridership'], periods=[24, 24*7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_residuals_df(hourly_subway_df, hourly_bus_df, weather_df, subway_decomposition, bus_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include rows with precipitation > 0\n",
    "rainy_df = combined_df[combined_df['Precipitation (in)'] > 0].copy()\n",
    "print(f\"Original dataset size: {len(combined_df)}\")\n",
    "print(f\"Dataset size with only precipitation > 0: {len(rainy_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run analysis\n",
    "time_intervals = [\n",
    "    TimeInterval('Spring', 'weekend', (12, 14))\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear': LinearModel(),\n",
    "    'GLM': GLMModel(),\n",
    "    'Quantile': QuantileModel(quantile=0.5),\n",
    "    'Robust': RobustModel(),\n",
    "    'GradientBoosting': GradientBoostingModel(),\n",
    "    'XGBoost': XGBoostModel(n_estimators=10),\n",
    "    'Naive': NaiveModel()\n",
    "}\n",
    "\n",
    "train_df, val_df = split_df_at_datetime(rainy_df, pd.Timestamp('2023-11-16'))\n",
    "\n",
    "results = {}\n",
    "\n",
    "modes = ['subway', 'bus']\n",
    "\n",
    "for time_interval in time_intervals:\n",
    "    for mode in modes:\n",
    "        print(f\"\\nAnalysis for {mode.capitalize()} - {time_interval.summary}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # results = run_model_analysis(models, combined_df, mode, season, day_type, hours)\n",
    "        \n",
    "        # for model_name, result in results.items():\n",
    "        #     print(f\"\\n{model_name} Results:\")\n",
    "        #     print(\"Metrics:\", result['train_metrics'])\n",
    "        #     print(\"Summary:\", result['summary'])\n",
    "\n",
    "        results[f'{mode}_{time_interval.summary}'] = run_model_analysis(models, train_df, mode, time_interval, val_df)\n",
    "\n",
    "        for model_name, result in results[f'{mode}_{time_interval.summary}'].items():\n",
    "            print(f\"\\n{model_name} Results:\")\n",
    "            print(\"Train Metrics:\", result['train_metrics'])\n",
    "            print(\"Train Residuals:\", result['train_residual'])\n",
    "            print(\"Validation Metrics:\", result['val_metrics'])\n",
    "            print(\"Validation Residuals:\", result['val_residual'])\n",
    "            print(\"Summary:\", result['summary'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots comparing train vs validation MAE for each condition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def autolabel(ax, rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', rotation=90)\n",
    "\n",
    "# Create a plot for each condition\n",
    "for time_interval in time_intervals:\n",
    "    for mode in modes:\n",
    "        \n",
    "        # Extract results for this condition\n",
    "        condition_results = results[f'{mode}_{time_interval.summary}']\n",
    "        \n",
    "        # Extract MAE values for each model\n",
    "        model_names = list(condition_results.keys())\n",
    "        train_maes = [result['train_metrics']['MAE'] for result in condition_results.values()]\n",
    "        val_maes = [result['val_metrics']['MAE'] for result in condition_results.values()]\n",
    "        \n",
    "        # Calculate mean absolute residuals\n",
    "        train_residuals = np.mean([abs(result['train_residual']) for result in condition_results.values()])\n",
    "        val_residuals = np.mean([abs(result['val_residual']) for result in condition_results.values()])\n",
    "\n",
    "        # Set up bar plot\n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        train_bars = ax.bar(x - width/2, train_maes, width, label='Train MAE')\n",
    "        val_bars = ax.bar(x + width/2, val_maes, width, label='Validation MAE')\n",
    "        \n",
    "        # Add horizontal lines for mean absolute residuals\n",
    "        ax.axhline(y=train_residuals, color='blue', linestyle=':', label='Train Mean Absolute Residual')\n",
    "        ax.axhline(y=val_residuals, color='orange', linestyle=':', label='Validation Mean Absolute Residual')\n",
    "\n",
    "        # Customize plot\n",
    "        ax.set_ylabel('Mean Absolute Error')\n",
    "        ax.set_title(f'Model Performance Comparison: {mode.capitalize()} - {time_interval.summary}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(model_names)\n",
    "        ax.legend()\n",
    "\n",
    "        # Add value labels on bars\n",
    "        autolabel(ax, train_bars)\n",
    "        autolabel(ax, val_bars)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific statsmodels warning\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='statsmodels')\n",
    "\n",
    "# Define time intervals for parameter search\n",
    "# time_intervals = [\n",
    "#     TimeInterval('Spring', 'weekend', (0, 8)),\n",
    "#     TimeInterval('Spring', 'weekend', (8, 16)),\n",
    "#     TimeInterval('Spring', 'weekend', (16, 24)),\n",
    "#     TimeInterval('Spring', 'weekday', (0, 8)),\n",
    "#     TimeInterval('Spring', 'weekday', (8, 16)),\n",
    "#     TimeInterval('Spring', 'weekday', (16, 24)),\n",
    "#     TimeInterval('Summer', 'weekend', (0, 8)),\n",
    "#     TimeInterval('Summer', 'weekend', (8, 16)),\n",
    "#     TimeInterval('Summer', 'weekend', (16, 24)),\n",
    "#     TimeInterval('Summer', 'weekday', (0, 8)),\n",
    "#     TimeInterval('Summer', 'weekday', (8, 16)),\n",
    "#     TimeInterval('Summer', 'weekday', (16, 24))\n",
    "# ]\n",
    "\n",
    "time_intervals = [\n",
    "    TimeInterval('Fall', 'weekend', (0, 8)),\n",
    "    TimeInterval('Fall', 'weekend', (8, 16)),\n",
    "    TimeInterval('Fall', 'weekend', (16, 24)),\n",
    "    TimeInterval('Fall', 'weekday', (0, 8)),\n",
    "    TimeInterval('Fall', 'weekday', (8, 16)),\n",
    "    TimeInterval('Fall', 'weekday', (16, 24)),\n",
    "    TimeInterval('Winter', 'weekend', (0, 8)),\n",
    "    TimeInterval('Winter', 'weekend', (8, 16)),\n",
    "    TimeInterval('Winter', 'weekend', (16, 24)),\n",
    "    TimeInterval('Winter', 'weekday', (0, 8)),\n",
    "    TimeInterval('Winter', 'weekday', (8, 16)),\n",
    "    TimeInterval('Winter', 'weekday', (16, 24))\n",
    "]\n",
    "\n",
    "# Get all possible feature combinations\n",
    "feature_combinations = generate_feature_combinations([\n",
    "    ModelParameters.TEMPERATURE,\n",
    "    ModelParameters.PRECIPITATION, \n",
    "    ModelParameters.HUMIDITY,\n",
    "    ModelParameters.CLOUD_COVER,\n",
    "    ModelParameters.PRESSURE\n",
    "])\n",
    "\n",
    "# print(f\"Number of feature combinations: {len(feature_combinations)}\")\n",
    "# for i, combo in enumerate(feature_combinations):\n",
    "#     print(f\"{i}: {combo}\")\n",
    "\n",
    "# Run parameter search for each mode\n",
    "modes = ['subway', 'bus']\n",
    "search_results = {}\n",
    "\n",
    "for mode in modes:\n",
    "    # Evaluate models with different parameter combinations\n",
    "    mode_results = search_models_and_parameters(\n",
    "        models=models,\n",
    "        train_data=train_df,\n",
    "        val_data=val_df,\n",
    "        mode=mode,\n",
    "        time_intervals=time_intervals,\n",
    "        parameter_combinations=feature_combinations\n",
    "    )    \n",
    "    # Store results\n",
    "    search_results[mode] = mode_results\n",
    "\n",
    "\n",
    "    ordered_mode_results = order_averaged_scores(mode_results, mae_objective)\n",
    "\n",
    "    print(f\"Ordered mode results {ordered_mode_results}:\")\n",
    "    # Print top 5 feature combinations for this mode\n",
    "    n = 50\n",
    "    print(f\"\\nTop {n} feature combinations for {mode}:\")\n",
    "    for (model_name, params, score) in ordered_mode_results[:n]:\n",
    "        param_names = [p.value for p in params]\n",
    "        print(f\"Score: {score:.4f} - Features: {param_names} - Model: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_by_interval(search_results, mode, day_type):\n",
    "    best_models = {}\n",
    "    \n",
    "    # Get all results for this mode\n",
    "    mode_results = search_results[mode]\n",
    "    \n",
    "    # Filter results by day type and find best model for each interval\n",
    "    for result in mode_results:\n",
    "        interval = result[\"time_interval\"]\n",
    "        if interval.day_type != day_type:\n",
    "            continue\n",
    "            \n",
    "        model_results = result[\"model_results\"]\n",
    "        parameters = result[\"parameters\"]\n",
    "        \n",
    "        # Initialize best configuration for this interval if not exists\n",
    "        if interval not in best_models:\n",
    "            best_models[interval] = {\n",
    "                'model_name': None,\n",
    "                'features': None,\n",
    "                'train_mae': float('inf'),\n",
    "                'val_mae': float('inf'),\n",
    "                'val_residual': None,\n",
    "                'n_samples': 0\n",
    "            }\n",
    "            \n",
    "        # Check each model's performance\n",
    "        for model_name, metrics in model_results.items():\n",
    "            val_mae = metrics['val_metrics']['MAE']\n",
    "            if val_mae < best_models[interval]['val_mae']:\n",
    "                best_models[interval] = {\n",
    "                    'model_name': model_name,\n",
    "                    'features': [p.value for p in parameters],\n",
    "                    'train_mae': metrics['train_metrics']['MAE'],\n",
    "                    'val_mae': val_mae,\n",
    "                    'val_residual': np.mean(np.abs(metrics['val_residual'])),\n",
    "                    'n_samples_val': len(metrics['val_residual']),\n",
    "                    'n_samples_train': len(metrics['train_residual'])\n",
    "                }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Rest of the plotting code remains the same...\n",
    "\n",
    "# Create plots for each mode and day type\n",
    "for mode in modes:\n",
    "    for day_type in ['weekend', 'weekday']:\n",
    "        best_models = get_best_models_by_interval(search_results, mode, day_type)\n",
    "        \n",
    "        # Set up the plot\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        intervals = [interval.summary for interval in best_models.keys()]\n",
    "        x = np.arange(len(intervals))\n",
    "        width = 0.25\n",
    "        \n",
    "        # Create bars\n",
    "        train_bars = ax.bar(x - width, [m['train_mae'] for m in best_models.values()], width, label='Train MAE')\n",
    "        val_bars = ax.bar(x, [m['val_mae'] for m in best_models.values()], width, label='Validation MAE')\n",
    "        residual_bars = ax.bar(x + width, [m['val_residual'] for m in best_models.values()], width, label='Mean Abs Residual')\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_ylabel('Error Metrics')\n",
    "        ax.set_title(f'Best Model Performance by Time Interval\\n{mode.capitalize()} - {day_type.capitalize()}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(intervals)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add model details as annotations\n",
    "        for idx, (interval, model) in enumerate(best_models.items()):\n",
    "            ax.text(idx, 0, \n",
    "                   f\"Model: {model['model_name']}\\nFeatures: {', '.join(model['features'])}\\nn_val={model['n_samples_val']}\\nn_train={model['n_samples_train']}\", \n",
    "                   rotation=90, \n",
    "                   va='bottom', \n",
    "                   ha='center',\n",
    "                   fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mta_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
